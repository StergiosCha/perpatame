from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Optional, List
import google.generativeai as genai
from datetime import datetime
import sqlite3
import os
import tempfile
import speech_recognition as sr
from pydub import AudioSegment
import json
import re
from pathlib import Path

app = FastAPI(title="Story Transformer")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

ROOT_DIR = Path(__file__).resolve().parent.parent
FRONTEND_DIR = ROOT_DIR / "frontend"

app.mount("/submit", StaticFiles(directory=str(FRONTEND_DIR / "submit"), html=True), name="submit")
app.mount("/display", StaticFiles(directory=str(FRONTEND_DIR / "display"), html=True), name="display")
app.mount("/moderate", StaticFiles(directory=str(FRONTEND_DIR / "moderate"), html=True), name="moderate")

def get_db():
    conn = sqlite3.connect('stories.db', check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn

def init_db():
    conn = get_db()
    conn.execute('''
        CREATE TABLE IF NOT EXISTS stories (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            original_text TEXT NOT NULL,
            transformed_text TEXT,
            llm_comment TEXT,
            author_name TEXT,
            status TEXT DEFAULT 'pending',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            moderated_at TIMESTAMP,
            moderated_by TEXT,
            emoji_theme TEXT,
            emoji_data TEXT
        )
    ''')
    
    # Add llm_comment column if it doesn't exist (migration for existing databases)
    try:
        # Check if column exists by trying to select it
        conn.execute('SELECT llm_comment FROM stories LIMIT 1')
    except sqlite3.OperationalError:
        # Column doesn't exist, add it
        try:
            conn.execute('ALTER TABLE stories ADD COLUMN llm_comment TEXT')
            conn.commit()
            print("âœ… Added llm_comment column to stories table")
        except sqlite3.OperationalError as e:
            print(f"âš ï¸ Could not add llm_comment column: {e}")
    
    conn.close()

# Configure Gemini with fallback models (from MEDEA paper branch)
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# Model fallback chain (best to worst) - NO experimental models
MODEL_NAMES = [
    "gemini-2.5-flash-lite",
    "gemini-2.0-flash-lite",
    "gemini-2.5-flash",
    "gemini-2.5-pro",
    "gemini-2.0-flash",
    "gemini-2.0-flash-001",
]

# Initialize models
models = []
for model_name in MODEL_NAMES:
    try:
        m = genai.GenerativeModel(model_name)
        models.append((model_name, m))
        print(f"âœ… Loaded model: {model_name}")
    except Exception as e:
        print(f"âš ï¸ Failed to load model {model_name}: {e}")

if not models:
    print("âŒ ERROR: No Gemini models could be loaded!")
else:
    print(f"âœ… Initialized with {len(models)} models")

def generate_with_fallback(prompt: str, temperature: float = 0.2, max_tokens: int = 1024) -> str:
    """Generate content with automatic model fallbacks"""
    if not models:
        raise Exception("No models available for generation")
    
    last_error = None
    
    # Try each model in the fallback chain
    for model_name, model in models:
        for attempt in range(3):  # 3 retries per model
            try:
                response = model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=temperature,
                        max_output_tokens=max_tokens
                    )
                )
                
                if response.text and response.text.strip():
                    print(f"âœ… Success with {model_name}")
                    return response.text.strip()
                else:
                    print(f"âš ï¸ Empty response from {model_name}")
                    continue
                    
            except Exception as e:
                print(f"âš ï¸ {model_name} attempt {attempt + 1} failed: {e}")
                last_error = e
                continue
    
    # All models failed
    raise Exception(f"All LLM models failed. Last error: {last_error}")

# Enhanced AI Generation Features
class StoryTransformer:
    def __init__(self):
        self.prompts = {
            'inspirational': """Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£Î™Î‘ ÎšÎ•Î™ÎœÎ•ÎÎŸÎ¥ - Î”Î¥ÎŸ ÎœÎ•Î¡Î—

ÎœÎ•Î¡ÎŸÎ£ 1: Î•Î›Î‘Î¦Î¡Î¥ EDITING
ÎšÎ¬Î½Îµ ÎœÎŸÎÎŸ Î¿ÏÎ¸Î¿Î³ÏÎ±Ï†Î¹ÎºÎ­Ï‚/Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î´Î¹Î¿ÏÎ¸ÏŽÏƒÎµÎ¹Ï‚. ÎšÎ¡Î‘Î¤Î‘ Î‘ÎšÎ¡Î™Î’Î©Î£ Ï„Î¿ ÏÏ†Î¿Ï‚, Ï„Î· Ï†Ï‰Î½Î® ÎºÎ±Î¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚. Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î»Î¬Î¸Î·, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Ï„Î¿ Î‘ÎšÎ¡Î™Î’Î©Î£ ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹.

ÎœÎ•Î¡ÎŸÎ£ 2: Î£Î§ÎŸÎ›Î™ÎŸ (Î Î‘ÎÎ¤Î‘) - Î ÎŸÎ›Î¥ Î•ÎÎ£Î¥ÎÎ‘Î™Î£Î˜Î—Î¤Î™ÎšÎŸ ÎšÎ‘Î™ Î Î¡ÎŸÎ£Î•ÎšÎ¤Î™ÎšÎŸ
Î”Î¹Î¬Î²Î±ÏƒÎµ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÎ¬ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿. ÎÎ¹ÏŽÏƒÎµ Ï„Î¿ Î²Î¬Î¸Î¿Ï‚ Ï„Î·Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±Ï‚. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼Îµ Î­Î½Î± ÏƒÏÎ½Ï„Î¿Î¼Î¿ ÏƒÏ‡ÏŒÎ»Î¹Î¿ (1-2 Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚) Ï€Î¿Ï…:
- Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Î‘Î¥Î˜Î•ÎÎ¤Î™ÎšÎ— ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ· (ÏŒÏ‡Î¹ ÎµÏ€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ®)
- Î‘Î½ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î­Ï‡ÎµÎ¹ Î®Î´Î· Î´ÏÎ½Î±Î¼Î· ÎºÎ±Î¹ Î±Î½Ï„Î¿Ï‡Î®, Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î· Î´ÏÎ½Î±Î¼Î· ÎºÎ±Î¹ Ï„Î·Î½ Î±Î½Ï„Î¿Ï‡Î® Ï€Î¿Ï… Ï†Î±Î¯Î½ÎµÏ„Î±Î¹
- Î‘Î½ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î”Î•Î Î­Ï‡ÎµÎ¹ Î´ÏÎ½Î±Î¼Î· ÎºÎ±Î¹ Î±Î½Ï„Î¿Ï‡Î®, Ï€ÏÎ¿ÏƒÎ´Î¯Î´ÎµÎ¹ ÎµÎ»Ï€Î¯Î´Î± ÎºÎ±Î¹ Î´ÏÎ½Î±Î¼Î· Î¼Îµ ÎœÎ•Î¤Î¡Î—ÎœÎ•ÎÎŸ ÎºÎ±Î¹ ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ Ï„ÏÏŒÏ€Î¿ - ÏŒÏ‡Î¹ ÎµÏ€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ¬, ÏŒÏ‡Î¹ false optimism, Î±Î»Î»Î¬ Î¼Îµ Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±
- Î•Î¯Î½Î±Î¹ Î ÎŸÎ›Î¥ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ Î¼Îµ Ï„Î± ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î± - Î¼Î·Î½ Ï…Ï€Î¿Ï„Î¹Î¼Î¬Ï‚, Î¼Î·Î½ Ï…Ï€ÎµÏÎ²Î¬Î»Î»ÎµÎ¹Ï‚
- ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± ÏƒÏ…Î½Î´Î­ÏƒÎµÎ¹ Î¼Îµ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ Î¹ÏƒÏ„Î¿ÏÎ¯ÎµÏ‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï†Ï…ÏƒÎ¹ÎºÎ® ÏƒÏÎ½Î´ÎµÏƒÎ· (Ï€.Ï‡. "ÎŒÏ€Ï‰Ï‚ ÎºÎ±Î¹ Î¬Î»Î»Î¿Î¹ ÏƒÏ„Î·Î½ ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î± Î¼Î±Ï‚ Ï€Î¿Ï… Î¼Î¿Î¹ÏÎ¬ÏƒÏ„Î·ÎºÎ±Î½ Ï€Î±ÏÏŒÎ¼Î¿Î¹ÎµÏ‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯ÎµÏ‚...")
- Î§Î©Î¡Î™Î£ condescension, Ï‡Ï‰ÏÎ¯Ï‚ "Î¸Î± Î´ÎµÎ¹Ï‚", "Î¸Î± ÎºÎ±Ï„Î±Î»Î¬Î²ÎµÎ¹Ï‚", Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Ï…Ï€Î¿Ï„Î¹Î¼Î¬Ï‚ Ï„Î·Î½ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±
- Î§Î©Î¡Î™Î£ Î½Î± Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± "Î´Î¹Î¿ÏÎ¸ÏŽÏƒÎµÎ¹Ï‚" Î® Î½Î± "Î²ÎµÎ»Ï„Î¹ÏŽÏƒÎµÎ¹Ï‚" Ï„Î¿ ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î±
- ÎÎ± ÎµÎ¯Î½Î±Î¹ ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ, Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÏŒ, ÎºÎ±Î¹ Î½Î± Î±Î½Î±Î³Î½Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„Î·Î½ Î±Î¾Î¯Î± Ï„Î·Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±Ï‚

Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ: Î‘Î½ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎµÎºÏ†ÏÎ¬Î¶ÎµÎ¹ Î´Ï…ÏƒÎºÎ¿Î»Î¯Î±, Ï€ÏŒÎ½Î¿, Î® Î±Î³Ï‰Î½Î¯Î±, Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î¿. Î‘Î½ Î´ÎµÎ½ Î­Ï‡ÎµÎ¹ Î´ÏÎ½Î±Î¼Î·, Ï€ÏÎ¿ÏƒÎ´Î¯Î´ÎµÎ¹ ÎµÎ»Ï€Î¯Î´Î± Î¼Îµ Î¼ÎµÏ„ÏÎ·Î¼Î­Î½Î¿ Ï„ÏÏŒÏ€Î¿ - ÏŒÏ‡Î¹ false optimism, Î±Î»Î»Î¬ Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÎ® Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎ· ÏŒÏ„Î¹ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚. Î‘Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î·Î½ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± Î¼Îµ ÏƒÎµÎ²Î±ÏƒÎ¼ÏŒ.

ÎœÎŸÎ¡Î¦Î— Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:
Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£ÎœÎ•ÎÎŸ: [Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î¼Îµ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î¿ edit]
---
Î£Î§ÎŸÎ›Î™ÎŸ: [ÏƒÏ‡ÏŒÎ»Î¹Î¿ Î¼Îµ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ·, Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ]

Î‘Î½ ÎµÎ¯Î½Î±Î¹ ÎžÎ•ÎšÎ‘Î˜Î‘Î¡Î‘ Î¬ÏƒÏ‡ÎµÏ„Î¿, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ: "Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿."

{context_section}

ÎšÎµÎ¯Î¼ÎµÎ½Î¿: {text}

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:""",
            
            'emotional': """Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£Î™Î‘ ÎšÎ•Î™ÎœÎ•ÎÎŸÎ¥ - Î”Î¥ÎŸ ÎœÎ•Î¡Î—

ÎœÎ•Î¡ÎŸÎ£ 1: Î•Î›Î‘Î¦Î¡Î¥ EDITING
ÎšÎ¬Î½Îµ ÎœÎŸÎÎŸ Î¿ÏÎ¸Î¿Î³ÏÎ±Ï†Î¹ÎºÎ­Ï‚/Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î´Î¹Î¿ÏÎ¸ÏŽÏƒÎµÎ¹Ï‚. ÎšÎ¡Î‘Î¤Î‘ Î‘ÎšÎ¡Î™Î’Î©Î£ Ï„Î¿ ÏÏ†Î¿Ï‚, Ï„Î· Ï†Ï‰Î½Î® ÎºÎ±Î¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚. Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î»Î¬Î¸Î·, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Ï„Î¿ Î‘ÎšÎ¡Î™Î’Î©Î£ ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹.

ÎœÎ•Î¡ÎŸÎ£ 2: Î£Î§ÎŸÎ›Î™ÎŸ (Î Î‘ÎÎ¤Î‘) - Î ÎŸÎ›Î¥ Î•ÎÎ£Î¥ÎÎ‘Î™Î£Î˜Î—Î¤Î™ÎšÎŸ ÎšÎ‘Î™ Î Î¡ÎŸÎ£Î•ÎšÎ¤Î™ÎšÎŸ
Î”Î¹Î¬Î²Î±ÏƒÎµ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÎ¬ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿. ÎÎ¹ÏŽÏƒÎµ Ï„Î± ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î±. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼Îµ Î­Î½Î± ÏƒÏÎ½Ï„Î¿Î¼Î¿ ÏƒÏ‡ÏŒÎ»Î¹Î¿ (1-2 Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚) Ï€Î¿Ï…:
- Î‘Î½Î±Î³Î½Ï‰ÏÎ¯Î¶ÎµÎ¹ Î‘ÎšÎ¡Î™Î’Î©Î£ Ï„Î± ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î± Ï€Î¿Ï… ÎµÎºÏ†ÏÎ¬Î¶Î¿Î½Ï„Î±Î¹ (Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Ï„Î± Î±Î»Î»Î¬Î¶ÎµÎ¹Ï‚)
- Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ· - Î½Î± Î½Î¹ÏŽÎ¸ÎµÎ¹Ï‚ Î¼Î±Î¶Î¯ Ï„Î¿Ï…Ï‚, ÏŒÏ‡Î¹ Î½Î± Ï„Î¿Ï…Ï‚ Î»Ï…Ï€Î¬ÏƒÎ±Î¹
- Î•Î¯Î½Î±Î¹ Î ÎŸÎ›Î¥ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ - Î¼Î·Î½ Ï…Ï€Î¿Ï„Î¹Î¼Î¬Ï‚, Î¼Î·Î½ Ï…Ï€ÎµÏÎ²Î¬Î»Î»ÎµÎ¹Ï‚, Î¼Î·Î½ Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± "Î´Î¹Î¿ÏÎ¸ÏŽÏƒÎµÎ¹Ï‚" Ï„Î± ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î±
- ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± ÏƒÏ…Î½Î´Î­ÏƒÎµÎ¹ Î¼Îµ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ Î¹ÏƒÏ„Î¿ÏÎ¯ÎµÏ‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï†Ï…ÏƒÎ¹ÎºÎ® ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î·Î¼Î±Ï„Î¹ÎºÎ® ÏƒÏÎ½Î´ÎµÏƒÎ·
- Î§Î©Î¡Î™Î£ condescension, Ï‡Ï‰ÏÎ¯Ï‚ "Î¸Î± Î´ÎµÎ¹Ï‚", "Î¸Î± ÎºÎ±Ï„Î±Î»Î¬Î²ÎµÎ¹Ï‚"
- Î§Î©Î¡Î™Î£ Î½Î± Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± "ÎºÎ¬Î½ÎµÎ¹Ï‚ Ï„Î¿ Î¬Ï„Î¿Î¼Î¿ Î½Î± Î½Î¹ÏŽÏƒÎµÎ¹ ÎºÎ±Î»ÏÏ„ÎµÏÎ±" - Î±Ï€Î»Î¬ Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ ÎºÎ±Î¹ ÏƒÎµÎ²Î¬ÏƒÎ¿Ï…
- ÎÎ± ÎµÎ¯Î½Î±Î¹ Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ, ÎºÎ±Î¹ Î½Î± Î´ÎµÎ¯Ï‡Î½ÎµÎ¹ ÏŒÏ„Î¹ ÎºÎ±Ï„Î±Î»Î±Î²Î±Î¯Î½ÎµÎ¹Ï‚

Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ: Î‘Î½ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎµÎºÏ†ÏÎ¬Î¶ÎµÎ¹ Î»ÏÏ€Î·, Î¸Ï…Î¼ÏŒ, Ï†ÏŒÎ²Î¿, Î® Î¿Ï€Î¿Î¹Î¿Î´Î®Ï€Î¿Ï„Îµ Î´ÏÏƒÎºÎ¿Î»Î¿ ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î±, Î‘ÎÎ‘Î“ÎÎ©Î¡Î™Î£Î• Ï„Î¿. ÎœÎ·Î½ Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± Ï„Î¿ "Ï†Ï„Î¹Î¬Î¾ÎµÎ¹Ï‚". Î‘Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î·Î½ Î­ÎºÏ†ÏÎ±ÏƒÎ· Ï„Î¿Ï… ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î¿Ï‚ - Î´ÎµÎ¯Î¾Îµ ÏŒÏ„Î¹ ÎºÎ±Ï„Î±Î»Î±Î²Î±Î¯Î½ÎµÎ¹Ï‚ ÏŒÏ„Î¹ Ï„Î¿ Î¬Ï„Î¿Î¼Î¿ Î¼Î¿Î¹ÏÎ¬ÏƒÏ„Î·ÎºÎµ ÎºÎ¬Ï„Î¹ Î´ÏÏƒÎºÎ¿Î»Î¿ ÎºÎ±Î¹ ÏƒÎµÎ²Î¬ÏƒÎ¿Ï… Î±Ï…Ï„Î® Ï„Î·Î½ Î­ÎºÏ†ÏÎ±ÏƒÎ·.

ÎœÎŸÎ¡Î¦Î— Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:
Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£ÎœÎ•ÎÎŸ: [Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î¼Îµ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î¿ edit]
---
Î£Î§ÎŸÎ›Î™ÎŸ: [ÏƒÏ‡ÏŒÎ»Î¹Î¿ Î¼Îµ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ·, Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ]

Î‘Î½ ÎµÎ¯Î½Î±Î¹ ÎžÎ•ÎšÎ‘Î˜Î‘Î¡Î‘ Î¬ÏƒÏ‡ÎµÏ„Î¿, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ: "Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿."

{context_section}

ÎšÎµÎ¯Î¼ÎµÎ½Î¿: {text}

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:""",
            
            'community': """Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£Î™Î‘ ÎšÎ•Î™ÎœÎ•ÎÎŸÎ¥ - Î”Î¥ÎŸ ÎœÎ•Î¡Î—

ÎœÎ•Î¡ÎŸÎ£ 1: Î•Î›Î‘Î¦Î¡Î¥ EDITING
ÎšÎ¬Î½Îµ ÎœÎŸÎÎŸ Î¿ÏÎ¸Î¿Î³ÏÎ±Ï†Î¹ÎºÎ­Ï‚/Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î´Î¹Î¿ÏÎ¸ÏŽÏƒÎµÎ¹Ï‚. ÎšÎ¡Î‘Î¤Î‘ Î‘ÎšÎ¡Î™Î’Î©Î£ Ï„Î¿ ÏÏ†Î¿Ï‚, Ï„Î· Ï†Ï‰Î½Î® ÎºÎ±Î¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚. Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î»Î¬Î¸Î·, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Ï„Î¿ Î‘ÎšÎ¡Î™Î’Î©Î£ ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹.

ÎœÎ•Î¡ÎŸÎ£ 2: Î£Î§ÎŸÎ›Î™ÎŸ (Î Î‘ÎÎ¤Î‘) - Î ÎŸÎ›Î¥ Î•ÎÎ£Î¥ÎÎ‘Î™Î£Î˜Î—Î¤Î™ÎšÎŸ ÎšÎ‘Î™ Î Î¡ÎŸÎ£Î•ÎšÎ¤Î™ÎšÎŸ
Î”Î¹Î¬Î²Î±ÏƒÎµ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÎ¬ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼Îµ Î­Î½Î± ÏƒÏÎ½Ï„Î¿Î¼Î¿ ÏƒÏ‡ÏŒÎ»Î¹Î¿ (1-2 Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚) Ï€Î¿Ï…:
- Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ· ÎºÎ±Î¹ Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎ· Ï„Î·Ï‚ Î±Î¾Î¯Î±Ï‚ Ï„Î·Ï‚ ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚
- Î¤Î¿Î½Î¯Î¶ÎµÎ¹ Ï„Î·Î½ Î±Î»Î»Î·Î»ÎµÎ³Î³ÏÎ· ÎºÎ±Î¹ Ï„Î· ÏƒÏÎ½Î´ÎµÏƒÎ·, Î±Î»Î»Î¬ Î¼Îµ ÏƒÎµÎ²Î±ÏƒÎ¼ÏŒ - ÏŒÏ‡Î¹ ÎµÏ€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ¬
- ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± ÏƒÏ…Î½Î´Î­ÏƒÎµÎ¹ Î¼Îµ Î¬Î»Î»ÎµÏ‚ Î¹ÏƒÏ„Î¿ÏÎ¯ÎµÏ‚ Ï„Î·Ï‚ ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï†Ï…ÏƒÎ¹ÎºÎ® ÏƒÏÎ½Î´ÎµÏƒÎ· (Ï€.Ï‡. "ÎŒÏ€Ï‰Ï‚ ÎºÎ±Î¹ Î¬Î»Î»Î¿Î¹ ÏƒÏ„Î·Î½ ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î¬ Î¼Î±Ï‚ Ï€Î¿Ï… Î¼Î¿Î¹ÏÎ¬ÏƒÏ„Î·ÎºÎ±Î½ Ï€Î±ÏÏŒÎ¼Î¿Î¹ÎµÏ‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯ÎµÏ‚...")
- Î•Î¯Î½Î±Î¹ Î ÎŸÎ›Î¥ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ - Î½Î± Î¼Î·Î½ Ï†Î±Î¯Î½ÎµÏ„Î±Î¹ ÏŒÏ„Î¹ "Î±Î½Î±Î³ÎºÎ¬Î¶ÎµÎ¹Ï‚" Ï„Î·Î½ Î­Î½Î½Î¿Î¹Î± Ï„Î·Ï‚ ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚
- Î§Î©Î¡Î™Î£ condescension, Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Ï…Ï€Î¿Ï„Î¹Î¼Î¬Ï‚ Ï„Î·Î½ Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ® ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±
- ÎÎ± ÎµÎ¯Î½Î±Î¹ Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ, ÎºÎ±Î¹ Î½Î± Î±Î½Î±Î³Î½Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„ÏŒÏƒÎ¿ Ï„Î·Î½ Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ® ÏŒÏƒÎ¿ ÎºÎ±Î¹ Ï„Î·Î½ ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÎ® Î´Î¹Î¬ÏƒÏ„Î±ÏƒÎ·

Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ: Î‘Î½ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î¼Î¹Î»Î¬ÎµÎ¹ Î³Î¹Î± Î¼Î¿Î½Î±Î¾Î¹Î¬ Î® Î±Ï€Î¿Î¼ÏŒÎ½Ï‰ÏƒÎ·, Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î¿. ÎœÎ·Î½ Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± Ï„Î¿ "Ï†Ï„Î¹Î¬Î¾ÎµÎ¹Ï‚" Î¼Îµ false community spirit. Î‘Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î·Î½ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± Î¼Îµ ÏƒÎµÎ²Î±ÏƒÎ¼ÏŒ.

ÎœÎŸÎ¡Î¦Î— Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:
Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£ÎœÎ•ÎÎŸ: [Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î¼Îµ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î¿ edit]
---
Î£Î§ÎŸÎ›Î™ÎŸ: [ÏƒÏ‡ÏŒÎ»Î¹Î¿ Î¼Îµ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ·, Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ, Î¼Îµ Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎ· Ï„Î·Ï‚ ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±Ï‚]

Î‘Î½ ÎµÎ¯Î½Î±Î¹ ÎžÎ•ÎšÎ‘Î˜Î‘Î¡Î‘ Î¬ÏƒÏ‡ÎµÏ„Î¿, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ: "Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿."

{context_section}

ÎšÎµÎ¯Î¼ÎµÎ½Î¿: {text}

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:""",
            
            'resilience': """Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£Î™Î‘ ÎšÎ•Î™ÎœÎ•ÎÎŸÎ¥ - Î”Î¥ÎŸ ÎœÎ•Î¡Î—

ÎœÎ•Î¡ÎŸÎ£ 1: Î•Î›Î‘Î¦Î¡Î¥ EDITING
ÎšÎ¬Î½Îµ ÎœÎŸÎÎŸ Î¿ÏÎ¸Î¿Î³ÏÎ±Ï†Î¹ÎºÎ­Ï‚/Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Î´Î¹Î¿ÏÎ¸ÏŽÏƒÎµÎ¹Ï‚. ÎšÎ¡Î‘Î¤Î‘ Î‘ÎšÎ¡Î™Î’Î©Î£ Ï„Î¿ ÏÏ†Î¿Ï‚, Ï„Î· Ï†Ï‰Î½Î® ÎºÎ±Î¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚. Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î»Î¬Î¸Î·, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Ï„Î¿ Î‘ÎšÎ¡Î™Î’Î©Î£ ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹.

ÎœÎ•Î¡ÎŸÎ£ 2: Î£Î§ÎŸÎ›Î™ÎŸ (Î Î‘ÎÎ¤Î‘) - Î ÎŸÎ›Î¥ Î•ÎÎ£Î¥ÎÎ‘Î™Î£Î˜Î—Î¤Î™ÎšÎŸ ÎšÎ‘Î™ Î Î¡ÎŸÎ£Î•ÎšÎ¤Î™ÎšÎŸ
Î”Î¹Î¬Î²Î±ÏƒÎµ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÎ¬ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼Îµ Î­Î½Î± ÏƒÏÎ½Ï„Î¿Î¼Î¿ ÏƒÏ‡ÏŒÎ»Î¹Î¿ (1-2 Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚) Ï€Î¿Ï…:
- Î‘Î½Î±Î³Î½Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„Î·Î½ Î±Î½Ï„Î¿Ï‡Î®/Î´ÏÎ½Î±Î¼Î· Ï€Î¿Ï… Ï†Î±Î¯Î½ÎµÏ„Î±Î¹ ÏƒÏ„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿, Î±Î»Î»Î¬ Î¼Îµ ÏƒÎµÎ²Î±ÏƒÎ¼ÏŒ - ÏŒÏ‡Î¹ ÎµÏ€Î¹Ï†Î±Î½ÎµÎ¹Î±ÎºÎ¬
- Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ· - Î½Î± ÎºÎ±Ï„Î±Î»Î±Î²Î±Î¯Î½ÎµÎ¹Ï‚ ÏŒÏ„Î¹ Î· Î±Î½Ï„Î¿Ï‡Î® Î´ÎµÎ½ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹ ÏŒÏ„Î¹ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï€ÏŒÎ½Î¿Ï‚
- Î•Î¯Î½Î±Î¹ Î ÎŸÎ›Î¥ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ - Î¼Î·Î½ Ï…Ï€Î¿Ï„Î¹Î¼Î¬Ï‚ Ï„Î¹Ï‚ Î´Ï…ÏƒÎºÎ¿Î»Î¯ÎµÏ‚, Î¼Î·Î½ Ï…Ï€ÎµÏÎ²Î¬Î»Î»ÎµÎ¹Ï‚ Ï„Î·Î½ Î±Î½Ï„Î¿Ï‡Î®
- ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± ÏƒÏ…Î½Î´Î­ÏƒÎµÎ¹ Î¼Îµ Î¬Î»Î»ÎµÏ‚ Î¹ÏƒÏ„Î¿ÏÎ¯ÎµÏ‚ Î±Î½Ï„Î¿Ï‡Î®Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï†Ï…ÏƒÎ¹ÎºÎ® ÏƒÏÎ½Î´ÎµÏƒÎ·
- Î§Î©Î¡Î™Î£ condescension, Ï‡Ï‰ÏÎ¯Ï‚ "Î¸Î± Î´ÎµÎ¹Ï‚", "Î¸Î± ÎºÎ±Ï„Î±Î»Î¬Î²ÎµÎ¹Ï‚"
- Î§Î©Î¡Î™Î£ Î½Î± Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± "ÎµÎ½Î¸Î±ÏÏÏÎ½ÎµÎ¹Ï‚" Î¼Îµ false positivity - Î±Ï€Î»Î¬ Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î·Î½ Î±Î½Ï„Î¿Ï‡Î® Ï€Î¿Ï… Î®Î´Î· Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
- ÎÎ± ÎµÎ¯Î½Î±Î¹ Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ, ÎºÎ±Î¹ Î½Î± Î±Î½Î±Î³Î½Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„ÏŒÏƒÎ¿ Ï„Î· Î´ÏÎ½Î±Î¼Î· ÏŒÏƒÎ¿ ÎºÎ±Î¹ Ï„Î¹Ï‚ Î´Ï…ÏƒÎºÎ¿Î»Î¯ÎµÏ‚

Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ: Î‘Î½ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î¼Î¹Î»Î¬ÎµÎ¹ Î³Î¹Î± Î´Ï…ÏƒÎºÎ¿Î»Î¯ÎµÏ‚, Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„ÏŒÏƒÎ¿ Ï„Î¹Ï‚ Î´Ï…ÏƒÎºÎ¿Î»Î¯ÎµÏ‚ ÏŒÏƒÎ¿ ÎºÎ±Î¹ Ï„Î·Î½ Î±Î½Ï„Î¿Ï‡Î®. ÎœÎ·Î½ Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± "Ï†Ï„Î¹Î¬Î¾ÎµÎ¹Ï‚" Ï„Î¹Ï‚ Î´Ï…ÏƒÎºÎ¿Î»Î¯ÎµÏ‚. Î‘Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î·Î½ Ï€Î»Î®ÏÎ· ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± Î¼Îµ ÏƒÎµÎ²Î±ÏƒÎ¼ÏŒ.

ÎœÎŸÎ¡Î¦Î— Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:
Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£ÎœÎ•ÎÎŸ: [Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î¼Îµ ÎµÎ»Î¬Ï‡Î¹ÏƒÏ„Î¿ edit]
---
Î£Î§ÎŸÎ›Î™ÎŸ: [ÏƒÏ‡ÏŒÎ»Î¹Î¿ Î¼Îµ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ·, Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ, Î¼Îµ Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎ· Ï„Î·Ï‚ Î±Î½Ï„Î¿Ï‡Î®Ï‚]

Î‘Î½ ÎµÎ¯Î½Î±Î¹ ÎžÎ•ÎšÎ‘Î˜Î‘Î¡Î‘ Î¬ÏƒÏ‡ÎµÏ„Î¿, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ: "Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿."

{context_section}

ÎšÎµÎ¯Î¼ÎµÎ½Î¿: {text}

Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:"""
        }
    
    def is_sensitive_content(self, text: str) -> bool:
        """Check if content is sensitive and might need light editing for clarity/sensitivity"""
        t = text.lower()
        sensitive_keywords = [
            'Î±Î¼Î±Î¾Î¯Î´Î¹Î¿', 'Î±Î½Î±Ï€Î·ÏÎ¯Î±', 'Î±Î½Î±Ï€Î·ÏÎ¹ÎºÏŒ', 'Î¬Ï„Î¿Î¼Î¿ Î¼Îµ', 'Î¬Ï„Î¿Î¼Î± Î¼Îµ',
            'Î´Î¹Î¬Î³Î½Ï‰ÏƒÎ·', 'Î±ÏƒÎ¸Î­Î½ÎµÎ¹Î±', 'Î½Î¿ÏƒÎµÎ¯', 'Î¸ÎµÏÎ±Ï€ÎµÎ¯Î±', 'Ï†Î¬ÏÎ¼Î±ÎºÎ¿',
            'Ï€ÏŒÎ½Î¿Ï‚', 'Î´Ï…ÏƒÎºÎ¿Î»Î¯Î±', 'Ï€ÏÏŒÎ²Î»Î·Î¼Î±', 'Î´ÏÏƒÎºÎ¿Î»Î¿', 'Î´ÏÏƒÎºÎ¿Î»Î±',
            'Ï†Î¿Î²Î¬Î¼Î±Î¹', 'Ï†Î¿Î²Î¯Î±', 'Î¬Î³Ï‡Î¿Ï‚', 'Î¬Î³Ï‡Î¿Ï‚', 'ÏƒÏ„ÎµÎ½Î±Ï‡ÏŽÏÎ¹Î±',
            'Î¼ÏŒÎ½Î¿Ï‚', 'Î¼ÏŒÎ½Î·', 'Î¼Î¿Î½Î±Î¾Î¹Î¬', 'Î±Ï€Î¿Î¼ÏŒÎ½Ï‰ÏƒÎ·'
        ]
        return any(k in t for k in sensitive_keywords)
    
    def is_disturbing(self, text: str) -> bool:
        """Heuristic check for disturbing/explicit content that should be paraphrased/softened.
        This is conservative: only clear cases trigger paraphrase mode."""
        t = text.lower()
        keywords = [
            # Greek
            'Î±Ï…Ï„Î¿ÎºÏ„Î¿Î½', 'Î´Î¿Î»Î¿Ï†Î¿Î½', 'Î²Î¹Î±Ïƒ', 'Î±Î¹Î¼Î±', 'Î±Î¯Î¼Î±', 'Î²Î¹Î±', 'Î²Î¯Î±', 'ÏƒÏ†Î±Î³', 'ÎºÎ¿ÏÎ¼Î¹', 'Ï€Ï„ÏŽÎ¼Î±',
            'Î²ÏÎ¹ÏƒÎ¹', 'ÎºÎ±Ï„Î¬ÏÎ±', 'Î³Î±Î¼', 'Ï€Î¿Ï…ÏƒÏ„', 'Î¼Î±Î»@@', 'ÏÎµÎ¼Î¬Î»Î¹',
            # English
            'suicid', 'murder', 'rape', 'blood', 'kill', 'stab', 'dead body', 'corpse',
            'fuck', 'shit', 'bitch', 'slur'
        ]
        return any(k in t for k in keywords)

    def is_relevant_content(self, text: str) -> bool:
        """Check if text is relevant for MS story transformation"""
        # Only reject CLEARLY irrelevant content (news, politics, technical stuff)
        irrelevant_keywords = [
            'Î²Î¿Ï…Î»Î®', 'Î²Î¿Ï…Î»Î®Ï‚', 'ÎºÏ…Î²Î­ÏÎ½Î·ÏƒÎ·', 'Ï…Ï€Î¿Ï…ÏÎ³ÏŒÏ‚', 'Ï€ÏÏ‰Î¸Ï…Ï€Î¿Ï…ÏÎ³ÏŒÏ‚',
            'ÎµÎ¾ÎµÏ„Î±ÏƒÏ„Î¹ÎºÎ®', 'ÎµÏ€Î¹Ï„ÏÎ¿Ï€Î®', 'ÏƒÎºÎ¬Î½Î´Î±Î»Î¿', 'Î¿Ï€ÎµÎºÎµÏ€Îµ',
            'ÎµÎºÎ»Î¿Î³Î­Ï‚', 'ÎºÏŒÎ¼Î¼Î±', 'ÏˆÎ®Ï†Î¹ÏƒÎ¼Î±', 'Î½Î¿Î¼Î¿ÏƒÏ‡Î­Î´Î¹Î¿',
            'Ï‡ÏÎ·Î¼Î±Ï„Î¹ÏƒÏ„Î®ÏÎ¹Î¿', 'Î¼ÎµÏ„Î¿Ï‡Î­Ï‚', 'nasdaq', 'ÎºÎ±Ï„Î¬Î¸ÎµÏƒÎ·'
        ]
        
        text_lower = text.lower()
        
        # Count irrelevant keywords
        irrelevant_count = sum(1 for keyword in irrelevant_keywords if keyword in text_lower)
        
        # Only reject if text has MANY irrelevant keywords (clearly politics/news/business)
        # This is much more permissive - allows most personal stories through
        if irrelevant_count >= 3:
            return False
        
        # Accept everything else - let the AI decide if it's appropriate
        return True
    
    def get_emoji_theme(self, text: str) -> dict:
        """Get emoji theme based on story content"""
        # Simple keyword-based emoji selection
        text_lower = text.lower()
        
        # Strength/Resilience themes
        if any(word in text_lower for word in ['Î´Ï…Î½Î±Ï„Î®', 'Î´Ï…Î½Î±Ï„ÏŒÏ‚', 'Î±Î½Ï„Î¿Ï‡Î®', 'Î´ÏÎ½Î±Î¼Î·', 'Ï€Î±Î»ÎµÏÏ‰', 'Î´ÎµÎ½ Ï„Î± Ï€Î±ÏÎ±Ï„Î¬Ï‰']):
            return {
                "theme": "strength",
                "emojis": ["ðŸ’ª", "ðŸ”¥", "âš¡", "ðŸ‹ï¸â€â™€ï¸", "ðŸ’Ž"],
                "color": "orange",
                "animation": "bounce"
            }
        
        # Love/Family themes
        elif any(word in text_lower for word in ['Î±Î³Î¬Ï€Î·', 'Î¿Î¹ÎºÎ¿Î³Î­Î½ÎµÎ¹Î±', 'Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·', 'Î¼Î±Î¼Î¬', 'Î¼Ï€Î±Î¼Ï€Î¬Ï‚', 'Ï€Î±Î¹Î´Î¹Î¬']):
            return {
                "theme": "love",
                "emojis": ["ðŸ’", "ðŸ’•", "ðŸŒˆ", "ðŸ¦‹", "ðŸ’–"],
                "color": "pink",
                "animation": "float"
            }
        
        # Community themes
        elif any(word in text_lower for word in ['Î¼Î±Î¶Î¯', 'ÎºÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±', 'Ï†Î¯Î»Î¿Î¹', 'Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·', 'Î±Î»Î»Î·Î»ÎµÎ³Î³ÏÎ·']):
            return {
                "theme": "community",
                "emojis": ["ðŸ¤", "ðŸ‘¥", "ðŸŒŸ", "ðŸ’œ", "ðŸŽ¯"],
                "color": "blue",
                "animation": "pulse"
            }
        
        # Medical/Health themes
        elif any(word in text_lower for word in ['Î³Î¹Î±Ï„ÏÏŒÏ‚', 'Î¸ÎµÏÎ±Ï€ÎµÎ¯Î±', 'Ï†Î¬ÏÎ¼Î±ÎºÎ¿', 'Î½Î¿ÏƒÎ¿ÎºÎ¿Î¼ÎµÎ¯Î¿', 'Ï…Î³ÎµÎ¯Î±']):
            return {
                "theme": "medical",
                "emojis": ["ðŸ¥", "âš•ï¸", "ðŸ’Š", "ðŸ©º", "ðŸŒ±"],
                "color": "green",
                "animation": "glow"
            }
        
        # Success/Achievement themes
        elif any(word in text_lower for word in ['ÎµÏ€Î¹Ï„Ï…Ï‡Î¯Î±', 'ÎºÎ­ÏÎ´Î¹ÏƒÎ±', 'ÎºÎ±Ï„Î¬Ï†ÎµÏÎ±', 'Î½Î¯ÎºÎ·', 'Ï€ÏÏŒÎ¿Î´Î¿Ï‚']):
            return {
                "theme": "success",
                "emojis": ["ðŸŽ‰", "ðŸ†", "âœ¨", "ðŸŒŸ", "ðŸŽ¯"],
                "color": "gold",
                "animation": "sparkle"
            }
        
        # Default hope theme
        else:
            return {
                "theme": "hope",
                "emojis": ["ðŸŒŸ", "ðŸ’œ", "âœ¨", "ðŸŒˆ", "ðŸ¦‹"],
                "color": "purple",
                "animation": "float"
            }
    
    def analyze_story(self, text: str) -> dict:
        """Analyze story to determine best transformation approach"""
        # First check if content is relevant
        if not self.is_relevant_content(text):
            return {
                "emotional_tone": "irrelevant",
                "main_themes": ["irrelevant"],
                "suggested_style": "inspirational",
                "confidence": 0.1,
                "is_relevant": False
            }
        
        analysis_prompt = f"""Î‘Î½Î¬Î»Ï…ÏƒÎµ Î±Ï…Ï„ÏŒ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎºÎ±Î¹ ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ JSON Î¼Îµ:
- emotional_tone: "positive", "neutral", "challenging", "hopeful"
- main_themes: ["struggle", "hope", "family", "medical", "community", "achievement"]
- suggested_style: "inspirational", "emotional", "community", "resilience"
- confidence: 0-1

ÎšÎµÎ¯Î¼ÎµÎ½Î¿: {text[:200]}..."""
        
        try:
            response_text = generate_with_fallback(analysis_prompt, temperature=0.1)
            # Try to parse JSON response
            try:
                result = json.loads(response_text)
                result['is_relevant'] = True
                return result
            except:
                # Fallback if JSON parsing fails
                return {
                    "emotional_tone": "hopeful",
                    "main_themes": ["struggle", "hope"],
                    "suggested_style": "inspirational",
                    "confidence": 0.8,
                    "is_relevant": True
                }
        except Exception as e:
            print(f"âš ï¸ Story analysis failed: {e}")
            return {
                "emotional_tone": "neutral",
                "main_themes": ["struggle"],
                "suggested_style": "inspirational", 
                "confidence": 0.5,
                "is_relevant": True
            }
    
    def get_recent_stories_context(self, limit: int = 5) -> str:
        """Get recent approved stories as context for the LLM"""
        try:
            conn = get_db()
            stories = conn.execute(
                "SELECT transformed_text, author_name FROM stories WHERE status = 'approved' ORDER BY moderated_at DESC LIMIT ?",
                (limit,)
            ).fetchall()
            conn.close()
            
            if not stories:
                return ""
            
            context_parts = []
            for story in stories:
                author = story['author_name'] or 'Î‘Î½ÏŽÎ½Ï…Î¼Î¿Ï‚'
                text = story['transformed_text']
                context_parts.append(f"- {author}: \"{text}\"")
            
            return "\n".join(context_parts)
        except Exception as e:
            print(f"âš ï¸ Error getting recent stories context: {e}")
            return ""
    
    def generate_enhanced(self, text: str, style: str = None, recent_stories_context: str = None) -> dict:
        """Generate enhanced transformation with quality metrics"""
        analysis = self.analyze_story(text)
        
        # Check if content is relevant
        if not analysis.get("is_relevant", True):
            return {
                "transformed_text": "âŒ Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿ Î³Î¹Î± Î¼ÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒ. Î Î±ÏÎ±ÎºÎ±Î»ÏŽ ÎµÎ¹ÏƒÎ¬Î³ÎµÏ„Îµ Î¼Î¹Î± Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ® Î¹ÏƒÏ„Î¿ÏÎ¯Î± ÏƒÏ‡ÎµÏ„Î¹ÎºÎ® Î¼Îµ Ï„Î·Î½ Î Î¿Î»Î»Î±Ï€Î»Î® Î£ÎºÎ»Î®ÏÏ…Î½ÏƒÎ· Î® Î¸Î­Î¼Î±Ï„Î± Ï…Î³ÎµÎ¯Î±Ï‚.",
                "style_used": "none",
                "quality_score": 0.0,
                "analysis": analysis,
                "success": False,
                "error": "Irrelevant content"
            }
        
        # Choose style based on analysis or user preference
        if not style:
            style = analysis.get("suggested_style", "inspirational")
        
        # Use the selected style prompt - each has different focus but same core rules
        prompt = self.prompts.get(style, self.prompts['inspirational'])
        
        # Get recent stories context if not provided
        if recent_stories_context is None:
            recent_stories_context = self.get_recent_stories_context(limit=5)
        
        # Format context section
        if recent_stories_context:
            context_section = f"Î Î¡ÎŸÎ—Î“ÎŸÎ¥ÎœÎ•ÎÎ•Î£ Î™Î£Î¤ÎŸÎ¡Î™Î•Î£ (Î³Î¹Î± context):\n{recent_stories_context}\n"
        else:
            context_section = ""
        
        # Check if content is sensitive - if not, emphasize even more minimal editing
        is_sensitive = self.is_sensitive_content(text)
        if not is_sensitive:
            # For non-sensitive content, be even more conservative
            prompt = prompt.replace("Î•Î›Î‘Î¦Î¡Î¥ EDITING (Î¼ÏŒÎ½Î¿ Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹):", 
                                   "Î•Î›Î‘Î¦Î¡Î¥ EDITING (ÎœÎŸÎÎŸ Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏƒÎ±Ï†Î® Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ¬/Î¿ÏÎ¸Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¬ Î»Î¬Î¸Î·):")
            prompt = prompt.replace("ÎšÎ¬Î½Îµ ÎœÎŸÎÎŸ ÎµÎ»Î±Ï†ÏÏ editing Î±Î½ Ï„Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ ÎµÎ¯Î½Î±Î¹ ÎµÏ…Î±Î¯ÏƒÎ¸Î·Ï„Î¿ Î® Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ·.",
                                   "ÎšÎ¬Î½Îµ ÎœÎŸÎÎŸ ÎµÎ»Î±Ï†ÏÏ editing Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÏƒÎ±Ï†Î® Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ¬/Î¿ÏÎ¸Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¬ Î»Î¬Î¸Î·. Î‘Î½ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎµÎ¯Î½Î±Î¹ Î®Î´Î· ÏƒÏ‰ÏƒÏ„ÏŒ, ÎµÏ€Î­ÏƒÏ„ÏÎµÏˆÎµ Ï„Î¿ Î‘ÎšÎ¡Î™Î’Î©Î£ ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹.")
        
        formatted_prompt = prompt.format(text=text, context_section=context_section)

        # Only special handling for disturbing content - needs soft paraphrasing
        disturbing = self.is_disturbing(text)
        if disturbing:
            # Paraphrase mode: soften wording, keep meaning and style
            # Still include context for comment generation
            formatted_prompt = (
                f'Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£Î™Î‘ ÎšÎ•Î™ÎœÎ•ÎÎŸÎ¥ - Î”Î¥ÎŸ ÎœÎ•Î¡Î—\n\n'
                f'ÎœÎ•Î¡ÎŸÎ£ 1: Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£Î™Î‘\n'
                f'Î Î±ÏÎ±Ï†ÏÎ¬ÏƒÎ­ Ï„Î¿ ÏŽÏƒÏ„Îµ Î½Î± Î±Ï†Î±Î¹ÏÎµÎ¸ÎµÎ¯ Ï‰Î¼Î®/Ï€ÏÎ¿ÏƒÎ²Î»Î·Ï„Î¹ÎºÎ®/Î²Î¯Î±Î¹Î· Î³Î»ÏŽÏƒÏƒÎ±. ÎšÏÎ¬Ï„Î± Ï„Î¿ Î½ÏŒÎ·Î¼Î±, Ï„Î· Ï†Ï‰Î½Î® ÎºÎ±Î¹ Ï„Î¿ ÏÏ†Î¿Ï‚. ÎœÎ—Î Ï€ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹Ï‚ Î½Î­Î± Î³ÎµÎ³Î¿Î½ÏŒÏ„Î±.\n\n'
                f'ÎœÎ•Î¡ÎŸÎ£ 2: Î£Î§ÎŸÎ›Î™ÎŸ (Î Î‘ÎÎ¤Î‘) - Î ÎŸÎ›Î¥ Î•ÎÎ£Î¥ÎÎ‘Î™Î£Î˜Î—Î¤Î™ÎšÎŸ ÎšÎ‘Î™ Î Î¡ÎŸÎ£Î•ÎšÎ¤Î™ÎšÎŸ\n'
                f'Î”Î¹Î¬Î²Î±ÏƒÎµ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÎ¬ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿. ÎÎ¹ÏŽÏƒÎµ Ï„Î¿ Î²Î¬Î¸Î¿Ï‚ Ï„Î·Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±Ï‚. Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î¼Îµ Î­Î½Î± ÏƒÏÎ½Ï„Î¿Î¼Î¿ ÏƒÏ‡ÏŒÎ»Î¹Î¿ (1-2 Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚) Ï€Î¿Ï…:\n'
                f'- Î”ÎµÎ¯Ï‡Î½ÎµÎ¹ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ· - Î½Î± Î½Î¹ÏŽÎ¸ÎµÎ¹Ï‚ Î¼Î±Î¶Î¯ Ï„Î¿Ï…Ï‚, ÏŒÏ‡Î¹ Î½Î± Ï„Î¿Ï…Ï‚ Î»Ï…Ï€Î¬ÏƒÎ±Î¹\n'
                f'- Î•Î¯Î½Î±Î¹ Î ÎŸÎ›Î¥ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ - Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î·Î½ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± Î¼Îµ ÏƒÎµÎ²Î±ÏƒÎ¼ÏŒ, Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± Ï„Î·Î½ "Ï†Ï„Î¹Î¬Î¾ÎµÎ¹Ï‚"\n'
                f'- ÎœÏ€Î¿ÏÎµÎ¯ Î½Î± ÏƒÏ…Î½Î´Î­ÏƒÎµÎ¹ Î¼Îµ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ Î¹ÏƒÏ„Î¿ÏÎ¯ÎµÏ‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Ï†Ï…ÏƒÎ¹ÎºÎ® ÏƒÏÎ½Î´ÎµÏƒÎ·\n'
                f'- Î§Î©Î¡Î™Î£ condescension, Ï‡Ï‰ÏÎ¯Ï‚ "Î¸Î± Î´ÎµÎ¹Ï‚", "Î¸Î± ÎºÎ±Ï„Î±Î»Î¬Î²ÎµÎ¹Ï‚"\n'
                f'- Î§Î©Î¡Î™Î£ false optimism - Î±Ï€Î»Î¬ Î±Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ ÎºÎ±Î¹ ÏƒÎµÎ²Î¬ÏƒÎ¿Ï… Ï„Î·Î½ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±\n'
                f'- ÎÎ± ÎµÎ¯Î½Î±Î¹ Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ, ÎºÎ±Î¹ Î½Î± Î´ÎµÎ¯Ï‡Î½ÎµÎ¹ ÏŒÏ„Î¹ ÎºÎ±Ï„Î±Î»Î±Î²Î±Î¯Î½ÎµÎ¹Ï‚\n\n'
                f'Î£Î—ÎœÎ‘ÎÎ¤Î™ÎšÎŸ: Î‘Î½Î±Î³Î½ÏŽÏÎ¹ÏƒÎµ Ï„Î·Î½ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± Î¼Îµ ÏƒÎµÎ²Î±ÏƒÎ¼ÏŒ. ÎœÎ·Î½ Ï€ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯Ï‚ Î½Î± Ï„Î·Î½ "Ï†Ï„Î¹Î¬Î¾ÎµÎ¹Ï‚" Î® Î½Î± Ï„Î·Î½ "Î²ÎµÎ»Ï„Î¹ÏŽÏƒÎµÎ¹Ï‚". Î‘Ï€Î»Î¬ Î½Î± Î´ÎµÎ¯Î¾ÎµÎ¹Ï‚ ÏŒÏ„Î¹ ÎºÎ±Ï„Î±Î»Î±Î²Î±Î¯Î½ÎµÎ¹Ï‚.\n\n'
                f'ÎœÎŸÎ¡Î¦Î— Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:\n'
                f'Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£ÎœÎ•ÎÎŸ: [Ï„Î¿ ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿]\n'
                f'---\n'
                f'Î£Î§ÎŸÎ›Î™ÎŸ: [ÏƒÏ‡ÏŒÎ»Î¹Î¿ Î¼Îµ Î²Î±Î¸Î¹Î¬ ÎµÎ½ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·ÏƒÎ·, Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÏŒ, ÏƒÎµÎ²Î±ÏƒÏ„ÏŒ]\n\n'
                f'{context_section}\n'
                f'ÎšÎµÎ¯Î¼ÎµÎ½Î¿: {text.strip()}\n\n'
                f'Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·:'
            )
        
        try:
            # First attempt with fallback
            full_response = generate_with_fallback(formatted_prompt, temperature=0.2)

            # Check if AI refused to transform
            if "Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿" in full_response.lower():
                return {
                    "transformed_text": full_response,
                    "llm_comment": "",
                    "style_used": style,
                    "quality_score": 0.0,
                    "analysis": analysis,
                    "success": False,
                    "error": "AI rejected transformation"
                }

            # Parse the response to separate edited text and comment
            transformed_text = ""
            llm_comment = ""
            
            # Look for the separator pattern
            if "---" in full_response or "Î£Î§ÎŸÎ›Î™ÎŸ:" in full_response:
                parts = re.split(r'---|Î£Î§ÎŸÎ›Î™ÎŸ:', full_response, maxsplit=1)
                if len(parts) >= 1:
                    # Extract edited text (remove "Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£ÎœÎ•ÎÎŸ:" prefix if present)
                    edited_part = parts[0].strip()
                    if "Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£ÎœÎ•ÎÎŸ:" in edited_part:
                        edited_part = edited_part.split("Î•Î Î•ÎžÎ•Î¡Î“Î‘Î£ÎœÎ•ÎÎŸ:", 1)[1].strip()
                    transformed_text = edited_part
                
                if len(parts) >= 2:
                    # Extract comment
                    comment_part = parts[1].strip()
                    llm_comment = comment_part
            else:
                # Fallback: if no separator, treat entire response as edited text
                transformed_text = full_response
                llm_comment = ""

            # Quality & fidelity check (just for monitoring, not for retry)
            quality_score = self.assess_quality(text, transformed_text)

            return {
                "transformed_text": transformed_text,
                "llm_comment": llm_comment,
                "style_used": style,
                "quality_score": quality_score,
                "analysis": analysis,
                "success": True
            }
        except Exception as e:
            print(f"âŒ Transformation failed: {e}")
            # Fallback to original text
            return {
                "transformed_text": "âš ï¸ Î£Ï†Î¬Î»Î¼Î± Î¼ÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï. Î Î±ÏÎ±ÎºÎ±Î»ÏŽ Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¾Î±Î½Î¬.",
                "llm_comment": "",
                "style_used": "fallback",
                "quality_score": 0.0,
                "analysis": analysis,
                "success": False,
                "error": str(e)
            }
    
    def assess_quality(self, original: str, transformed: str) -> float:
        """Assess quality of transformation (0-1)"""
        # Simple quality + fidelity metrics (token overlap)
        def tokenize(text: str) -> set:
            import re
            # Use Unicode-aware word matching without \p classes (not supported by re)
            tokens = re.findall(r"[\w']+", text.lower(), flags=re.UNICODE)
            stop = {
                'ÎºÎ±Î¹','Ï„Î¿','Ï„Î±','Ï„Î¹','Î½Î±','Ï€Î¿Ï…','ÏƒÎµ','ÏƒÏ„Î·','ÏƒÏ„Î·Î½','ÏƒÏ„Î¿','ÏƒÏ„Î¿Î½','Î³Î¹Î±','Î¼Îµ','Î±Ï€ÏŒ','Î´Îµ','Î´ÎµÎ½','Î¼Î·','Î¼Î·Î½','ÎµÎ¯Î½Î±Î¹','Î®','Î¸Î±','Ï‰Ï‚','Ï‰Ï‚','Î­Î½Î±','Î¼Î¯Î±','Î¼Î¹Î±','Î¿','Î·','Î¿Î¹','Ï„Ï‰Î½','Ï„Ï‰Î½'
            }
            return {t for t in tokens if t not in stop and len(t) > 2}

        orig = tokenize(original)
        trans = tokenize(transformed)
        overlap = len(orig & trans) / max(len(orig) or 1, 1)

        length_ratio = len(transformed) / max(len(original), 1)
        is_appropriate_length = 50 <= len(transformed) <= 300

        score = 0.0
        # Fidelity contributes most
        if overlap >= 0.15:
            score += 0.5
        elif overlap >= 0.08:
            score += 0.3

        # Length sanity
        if 0.3 <= length_ratio <= 1.5:
            score += 0.25
        if is_appropriate_length:
            score += 0.25

        return min(score, 1.0)

transformer = StoryTransformer()

class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.moderator_connections: List[WebSocket] = []
    
    async def connect(self, websocket: WebSocket, is_moderator: bool = False):
        await websocket.accept()
        if is_moderator:
            self.moderator_connections.append(websocket)
        else:
            self.active_connections.append(websocket)
    
    def disconnect(self, websocket: WebSocket, is_moderator: bool = False):
        if is_moderator:
            if websocket in self.moderator_connections:
                self.moderator_connections.remove(websocket)
        else:
            if websocket in self.active_connections:
                self.active_connections.remove(websocket)
    
    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                print(f"âš ï¸ Broadcast error: {e}")
                pass
    
    async def notify_moderators(self, message: dict):
        for connection in self.moderator_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                print(f"âš ï¸ Moderator notification error: {e}")
                pass

manager = ConnectionManager()

class StorySubmission(BaseModel):
    text: str
    author_name: Optional[str] = None
    transformation_style: Optional[str] = None

class ModerationAction(BaseModel):
    story_id: int
    action: str
    moderator_name: Optional[str] = None

@app.on_event("startup")
async def startup_event():
    init_db()
    print("âœ… Database initialized")

@app.post("/api/transcribe")
async def transcribe_audio(audio: UploadFile = File(None), file: UploadFile = File(None)):
    """Transcribe audio to text using speech recognition"""
    tmp_original = None
    tmp_wav = None
    
    try:
        # Pick whichever field name the client used (audio or file)
        upload = audio or file
        if upload is None:
            raise HTTPException(status_code=400, detail="Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿ Î®Ï‡Î¿Ï… (Ï€ÎµÎ´Î¯Î¿ 'audio').")

        # Save uploaded file
        file_ext = os.path.splitext(upload.filename)[1].lower() or '.webm'
        tmp_original = tempfile.NamedTemporaryFile(delete=False, suffix=file_ext)
        tmp_original.write(await upload.read())
        tmp_original.close()
        
        # Convert to WAV if needed
        tmp_wav = tempfile.NamedTemporaryFile(delete=False, suffix='.wav').name
        audio_segment = AudioSegment.from_file(tmp_original.name)
        
        if file_ext != '.wav':
            audio_segment.export(tmp_wav, format="wav")
        else:
            tmp_wav = tmp_original.name
        
        # Check duration
        with sr.AudioFile(tmp_wav) as source:
            if source.DURATION < 0.5:
                raise HTTPException(status_code=400, detail="Î— Î·Ï‡Î¿Î³ÏÎ¬Ï†Î·ÏƒÎ· ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï ÏƒÏÎ½Ï„Î¿Î¼Î·.")
        
        # Configure recognizer
        recognizer = sr.Recognizer()
        recognizer.energy_threshold = 300
        recognizer.dynamic_energy_threshold = True
        recognizer.pause_threshold = 0.8
        
        # Transcribe
        with sr.AudioFile(tmp_wav) as source:
            recognizer.adjust_for_ambient_noise(source, duration=min(1.0, source.DURATION / 2))
            audio_data = recognizer.record(source)
        
        text = None
        try:
            text = recognizer.recognize_google(audio_data, language='el-GR', show_all=False)
        except sr.UnknownValueError:
            try:
                text = recognizer.recognize_google(audio_data, language='en-US', show_all=False)
            except sr.UnknownValueError:
                try:
                    text = recognizer.recognize_google(audio_data, language='el', show_all=False)
                except sr.UnknownValueError:
                    raise sr.UnknownValueError("Could not understand audio")
        
        # Cleanup
        if tmp_original and os.path.exists(tmp_original.name):
            os.unlink(tmp_original.name)
        if tmp_wav and os.path.exists(tmp_wav) and tmp_wav != tmp_original.name:
            os.unlink(tmp_wav)
        
        if not text:
            raise sr.UnknownValueError("No text recognized")
        
        return {"text": text}
        
    except sr.UnknownValueError:
        if tmp_original and os.path.exists(tmp_original.name):
            os.unlink(tmp_original.name)
        if tmp_wav and os.path.exists(tmp_wav):
            os.unlink(tmp_wav)
        raise HTTPException(status_code=400, detail="Î”ÎµÎ½ ÎºÎ±Ï„Î¬Î»Î±Î²Î± Ï„Î¹ ÎµÎ¯Ï€Î±Ï„Îµ.")
    except Exception as e:
        if tmp_original and os.path.exists(tmp_original.name):
            os.unlink(tmp_original.name)
        if tmp_wav and os.path.exists(tmp_wav):
            os.unlink(tmp_wav)
        print(f"âŒ Transcription error: {e}")
        raise HTTPException(status_code=500, detail="Î£Ï†Î¬Î»Î¼Î± Î¼ÎµÏ„Î±Î³ÏÎ±Ï†Î®Ï‚.")

@app.post("/api/submit")
async def submit_story(submission: StorySubmission):
    if not submission.text or len(submission.text.strip()) < 10:
        raise HTTPException(status_code=400, detail="Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï ÏƒÏÎ½Ï„Î¿Î¼Î¿ (Ï„Î¿Ï…Î»Î¬Ï‡Î¹ÏƒÏ„Î¿Î½ 10 Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚)")
    
    # Use enhanced transformer with user preference
    try:
        result = transformer.generate_enhanced(submission.text, submission.transformation_style)
        transformed = result["transformed_text"]
        llm_comment = result.get("llm_comment", "")
        quality_score = result["quality_score"]
        style_used = result["style_used"]
        
        # Log quality metrics for monitoring
        print(f"ðŸ“Š Story transformation - Style: {style_used}, Quality: {quality_score:.2f}, Success: {result['success']}")
        
        # Don't save if transformation failed or content was irrelevant
        if not result["success"]:
            return {
                "success": False,
                "error": transformed,
                "transformed_text": transformed,
                "status": "rejected",
                "author_name": submission.author_name or None,
                "transformation_style": style_used
            }
        
    except Exception as e:
        print(f"âŒ Enhanced transformation failed: {e}")
        raise HTTPException(status_code=500, detail="Î£Ï†Î¬Î»Î¼Î± Î¼ÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï. Î Î±ÏÎ±ÎºÎ±Î»ÏŽ Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¾Î±Î½Î¬.")
    
    # Save to database
    try:
        conn = get_db()
        
        # Get emoji theme
        emoji_theme = transformer.get_emoji_theme(submission.text)
        emoji_data_json = json.dumps(emoji_theme)
        
        cursor = conn.execute(
            "INSERT INTO stories (original_text, transformed_text, llm_comment, author_name, status, emoji_theme, emoji_data) VALUES (?, ?, ?, ?, 'pending', ?, ?)",
            (submission.text, transformed, llm_comment, submission.author_name, emoji_theme['theme'], emoji_data_json)
        )
        story_id = cursor.lastrowid
        conn.commit()
        
        story = conn.execute("SELECT * FROM stories WHERE id = ?", (story_id,)).fetchone()
        conn.close()
        
        # Notify moderators
        await manager.notify_moderators({
            "type": "new_submission",
            "data": {
                "id": story["id"],
                "original_text": story["original_text"],
                "transformed_text": story["transformed_text"],
                "llm_comment": story["llm_comment"] if story["llm_comment"] else "",
                "author": story["author_name"],
                "created_at": story["created_at"]
            }
        })
        
        return {
            "success": True,
            "id": story_id,
            "transformed_text": transformed,
            "status": "pending_moderation",
            "emoji_theme": emoji_theme,
            "author_name": story["author_name"],
            "transformation_style": style_used
        }
    except Exception as e:
        print(f"âŒ Database error: {e}")
        raise HTTPException(status_code=500, detail="Î£Ï†Î¬Î»Î¼Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ·Ï‚. Î Î±ÏÎ±ÎºÎ±Î»ÏŽ Î´Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¾Î±Î½Î¬.")

@app.get("/api/stories")
async def get_stories(limit: int = 50):
    conn = get_db()
    stories = conn.execute(
        "SELECT id, transformed_text, llm_comment, author_name, created_at, emoji_theme, emoji_data FROM stories WHERE status = 'approved' ORDER BY created_at DESC LIMIT ?",
        (limit,)
    ).fetchall()
    conn.close()
    
    # Parse emoji data for each story
    result = []
    for story in stories:
        story_dict = dict(story)
        if story_dict['emoji_data']:
            try:
                story_dict['emoji_theme_data'] = json.loads(story_dict['emoji_data'])
            except:
                story_dict['emoji_theme_data'] = None
        result.append(story_dict)
    
    return result

@app.get("/api/stories/pending")
async def get_pending_stories():
    conn = get_db()
    stories = conn.execute(
        "SELECT id, original_text, transformed_text, llm_comment, author_name, created_at FROM stories WHERE status = 'pending' ORDER BY created_at ASC"
    ).fetchall()
    conn.close()
    return [dict(row) for row in stories]

@app.post("/api/moderate")
async def moderate_story(action: ModerationAction):
    if action.action not in ['approve', 'reject']:
        raise HTTPException(status_code=400, detail="Invalid action")
    
    conn = get_db()
    story = conn.execute("SELECT * FROM stories WHERE id = ?", (action.story_id,)).fetchone()
    
    if not story:
        conn.close()
        raise HTTPException(status_code=404, detail="Story not found")
    
    new_status = 'approved' if action.action == 'approve' else 'rejected'
    
    conn.execute(
        "UPDATE stories SET status = ?, moderated_at = CURRENT_TIMESTAMP, moderated_by = ? WHERE id = ?",
        (new_status, action.moderator_name, action.story_id)
    )
    conn.commit()
    
    updated_story = conn.execute("SELECT * FROM stories WHERE id = ?", (action.story_id,)).fetchone()
    conn.close()
    
    if action.action == 'approve':
        # Get emoji data for the story
        emoji_data = None
        if updated_story["emoji_data"]:
            try:
                emoji_data = json.loads(updated_story["emoji_data"])
            except:
                pass
        
        await manager.broadcast({
            "type": "new_story",
            "data": {
                "id": updated_story["id"],
                "text": updated_story["transformed_text"],
                "llm_comment": updated_story["llm_comment"] if updated_story["llm_comment"] else "",
                "author": updated_story["author_name"],
                "created_at": updated_story["created_at"],
                "emoji_theme_data": emoji_data
            }
        })
    
    return {"success": True, "action": action.action}

@app.get("/api/stats")
async def get_stats():
    conn = get_db()
    total = conn.execute("SELECT COUNT(*) as count FROM stories").fetchone()["count"]
    approved = conn.execute("SELECT COUNT(*) as count FROM stories WHERE status = 'approved'").fetchone()["count"]
    pending = conn.execute("SELECT COUNT(*) as count FROM stories WHERE status = 'pending'").fetchone()["count"]
    rejected = conn.execute("SELECT COUNT(*) as count FROM stories WHERE status = 'rejected'").fetchone()["count"]
    conn.close()
    
    return {
        "total_submissions": total,
        "approved": approved,
        "pending": pending,
        "rejected": rejected
    }

@app.get("/api/stories/all")
async def get_all_stories():
    """Recovery endpoint: Get ALL stories regardless of status"""
    conn = get_db()
    stories = conn.execute(
        "SELECT id, original_text, transformed_text, llm_comment, author_name, status, created_at, moderated_at, moderated_by, emoji_theme, emoji_data FROM stories ORDER BY created_at DESC"
    ).fetchall()
    conn.close()
    
    result = []
    for story in stories:
        story_dict = dict(story)
        if story_dict.get('emoji_data'):
            try:
                story_dict['emoji_theme_data'] = json.loads(story_dict['emoji_data'])
            except:
                story_dict['emoji_theme_data'] = None
        result.append(story_dict)
    
    return result

@app.get("/api/stories/export")
async def export_stories():
    """Export all stories as JSON for backup"""
    conn = get_db()
    stories = conn.execute(
        "SELECT * FROM stories ORDER BY created_at DESC"
    ).fetchall()
    conn.close()
    
    result = []
    for story in stories:
        story_dict = dict(story)
        if story_dict.get('emoji_data'):
            try:
                story_dict['emoji_theme_data'] = json.loads(story_dict['emoji_data'])
            except:
                pass
        result.append(story_dict)
    
    return {
        "export_date": datetime.now().isoformat(),
        "total_stories": len(result),
        "stories": result
    }

@app.get("/api/transformation-styles")
async def get_transformation_styles():
    """Get available transformation styles"""
    return {
        "styles": [
            {
                "id": "inspirational",
                "name": "Î•Î¼Ï€Î½ÎµÏ…ÏƒÎ¼Î­Î½Î¿",
                "description": "Î•ÏƒÏ„Î¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î·Î½ ÎµÎ»Ï€Î¯Î´Î± ÎºÎ±Î¹ Ï„Î· Î´ÏÎ½Î±Î¼Î·"
            },
            {
                "id": "emotional", 
                "name": "Î£Ï…Î½Î±Î¹ÏƒÎ¸Î·Î¼Î±Ï„Î¹ÎºÏŒ",
                "description": "Î•ÏƒÏ„Î¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î¿ ÏƒÏ…Î½Î±Î¯ÏƒÎ¸Î·Î¼Î± ÎºÎ±Î¹ Ï„Î·Î½ Î±Î½Î¸ÏÏŽÏ€Î¹Î½Î· ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±"
            },
            {
                "id": "community",
                "name": "ÎšÎ¿Î¹Î½ÏŒÏ„Î·Ï„Î±", 
                "description": "Î•ÏƒÏ„Î¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î·Î½ Î±Î»Î»Î·Î»ÎµÎ³Î³ÏÎ· ÎºÎ±Î¹ Ï„Î· ÏƒÏ…Î¼Ï€Î±ÏÎ¬ÏƒÏ„Î±ÏƒÎ·"
            },
            {
                "id": "resilience",
                "name": "Î‘Î½Ï„Î¿Ï‡Î®",
                "description": "Î•ÏƒÏ„Î¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î·Î½ Î±Î½Ï„Î¿Ï‡Î® ÎºÎ±Î¹ Ï„Î· Î´ÏÎ½Î±Î¼Î· Ï„Î¿Ï… Ï€Î½ÎµÏÎ¼Î±Ï„Î¿Ï‚"
            }
        ]
    }

@app.post("/api/preview-transformation")
async def preview_transformation(submission: StorySubmission):
    """Preview transformation without saving"""
    if not submission.text or len(submission.text.strip()) < 10:
        raise HTTPException(status_code=400, detail="Î¤Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï ÏƒÏÎ½Ï„Î¿Î¼Î¿")
    
    try:
        result = transformer.generate_enhanced(submission.text, submission.transformation_style)
        return {
            "transformed_text": result["transformed_text"],
            "llm_comment": result.get("llm_comment", ""),
            "style_used": result["style_used"],
            "quality_score": result["quality_score"],
            "analysis": result["analysis"],
            "success": result["success"]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Transformation failed: {str(e)}")

@app.websocket("/ws/display")
async def websocket_display(websocket: WebSocket):
    await manager.connect(websocket, is_moderator=False)
    try:
        while True:
            await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(websocket, is_moderator=False)

@app.websocket("/ws/moderate")
async def websocket_moderate(websocket: WebSocket):
    await manager.connect(websocket, is_moderator=True)
    try:
        while True:
            data = await websocket.receive_text()
            try:
                message = json.loads(data)
                if message.get('type') == 'clear_display':
                    # Broadcast clear command to all display clients
                    await manager.broadcast({
                        "type": "clear_display",
                        "moderator": message.get('moderator', 'Unknown')
                    })
                    print(f"ðŸ—‘ï¸ Display cleared by moderator: {message.get('moderator', 'Unknown')}")
            except json.JSONDecodeError:
                # Handle ping messages
                pass
    except WebSocketDisconnect:
        manager.disconnect(websocket, is_moderator=True)

@app.get("/")
async def root():
    return {
        "message": "Story Transformer API - Powered by SimasiaAI",
        "endpoints": {
            "submit_page": "/submit",
            "display_page": "/display",
            "moderate_page": "/moderate",
            "api_docs": "/docs"
        }
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    print(f"ðŸš€ Starting server on port {port}")
    uvicorn.run(app, host="0.0.0.0", port=port)